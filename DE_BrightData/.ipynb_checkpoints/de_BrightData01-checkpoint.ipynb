{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790f4bc2-13a6-4442-9046-a16d388e3a2d",
   "metadata": {},
   "source": [
    "# 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46e31b02-cee2-48f2-a080-bc9002d9eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aa2c4c-18b0-4e4f-9973-41f0aca66637",
   "metadata": {},
   "source": [
    "# 2. Read a txt file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b39d166-44bb-4bd8-94f3-94cf14b48926",
   "metadata": {},
   "source": [
    "## 2.1. Change to inputs directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a728eb-5ed9-4c0e-b528-7c0ada2dbca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/immanuel/Documents/NEU/05_Spring_2022/CS7675_ResAppr/tasks/MyLab/task14_de_BrightData\n",
      "/Users/immanuel/Documents/NEU/05_Spring_2022/CS7675_ResAppr/tasks/MyLab/task14_de_BrightData/inputs/logs\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "input_path_s = \"/inputs/logs\"\n",
    "input_path_s = os.getcwd() + input_path_s\n",
    "output_path_s = \"/outputs\"\n",
    "output_path_s = os.getcwd() + output_path_s\n",
    "os.chdir(input_path_s)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e460e1df-de0e-476a-9c23-4090224f450a",
   "metadata": {},
   "source": [
    "## 2.2. Read all txt log files and collect them in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7293e8b2-5472-4a3a-b312-5eed9eeeedae",
   "metadata": {},
   "outputs": [
    {
     "ename": "ParserError",
     "evalue": "Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zt/v6h22_cj7dv_pbkt59s8mxbh0000gn/T/ipykernel_51450/1366241319.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[0mlog_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtxt_filename\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"DUPLICATE LOG FILE: {txt_filename}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'log-brightdata'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mParserError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/zt/v6h22_cj7dv_pbkt59s8mxbh0000gn/T/ipykernel_51450/1366241319.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetsize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m500\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0mlog_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtxt_filename\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"\\n\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mon_bad_lines\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'skip'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mlog_d\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtxt_filename\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    584\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 586\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    587\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    588\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    486\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 488\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparser\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    489\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    490\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m   1045\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1046\u001b[0m         \u001b[0mnrows\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mvalidate_integer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"nrows\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1047\u001b[0;31m         \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcol_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1048\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1049\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mindex\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/io/parsers/c_parser_wrapper.py\u001b[0m in \u001b[0;36mread\u001b[0;34m(self, nrows)\u001b[0m\n\u001b[1;32m    221\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlow_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                 \u001b[0mchunks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_low_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnrows\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m                 \u001b[0;31m# destructive to chunks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_concatenate_chunks\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunks\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.read_low_memory\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._read_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/lib/python3.9/site-packages/pandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mParserError\u001b[0m: Error tokenizing data. C error: Buffer overflow caught - possible malformed input file.\n"
     ]
    }
   ],
   "source": [
    "log_d = dict()\n",
    "\n",
    "for file in glob.glob(\"*.txt\"):\n",
    "    \n",
    "    # Get the txt filename without the extension\n",
    "    txt_filename = os.path.splitext(file)[0]\n",
    "    \n",
    "    if txt_filename[:1].isdigit():\n",
    "    \n",
    "        # Parse AS number from txt_filename\n",
    "        dot_loc_i = txt_filename.find(\".\")\n",
    "        as_number_s = txt_filename[:dot_loc_i]\n",
    "\n",
    "        # If there is a number at the end of the filename, then remove.\n",
    "        if txt_filename[-1].isdigit():\n",
    "            txt_filename = txt_filename[:-1]\n",
    "\n",
    "        # Try whether txt_filename is in the dictionary\n",
    "        # If not, then assign into the dictionary\n",
    "        try:\n",
    "            log_d[txt_filename]\n",
    "            print(f\"DUPLICATE LOG FILE: {txt_filename}\")\n",
    "        except:\n",
    "            if os.path.getsize(file) > 500:\n",
    "                log_d[txt_filename] = pd.read_csv(file, sep=\"\\n\", header=None, on_bad_lines='skip')\n",
    "            else:\n",
    "                log_d[txt_filename] = pd.DataFrame()\n",
    "    \n",
    "print(len(log_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11bd0b2-38d8-4fd4-8248-1760a897496f",
   "metadata": {},
   "source": [
    "# 3. Count Request URL: FQDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3047b8d-687a-4733-9c9f-97d0d6c48012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_fqdn(request_series):\n",
    "    '''\n",
    "    parameter: path of txt files\n",
    "    output: list of txt files\n",
    "    does: Read all txt files in the path and creates a list of them\n",
    "    '''\n",
    "    fqdn_set = set()\n",
    "    is_reachable = True\n",
    "    for req in request_series:\n",
    "        if req[:15] == \"{'request url':\":\n",
    "            slash_loc_i = req.find(\"/\")\n",
    "            comma_loc_i = req.find(\",\")\n",
    "            url = req[slash_loc_i+2:comma_loc_i-1]\n",
    "\n",
    "            slash_loc_i = url.find(\"/\")\n",
    "            if slash_loc_i > 0:\n",
    "                url = url[:slash_loc_i]\n",
    "\n",
    "            question_mark_loc_i = url.find(\"?\")\n",
    "            if question_mark_loc_i > 0:\n",
    "                url = url[:question_mark_loc_i]\n",
    "\n",
    "            if \".\" in url:\n",
    "                fqdn_set.add(url)\n",
    "        else:\n",
    "            if req[-9:] == \"<unknown>\":\n",
    "                is_reachable = False         \n",
    "            \n",
    "    return fqdn_set, is_reachable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7228efb6-b34b-4aeb-abea-bed52c105ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_l = []\n",
    "domain_l = []\n",
    "as_number_l = []\n",
    "n_fqdn_response_l = []\n",
    "is_reachable_l = []\n",
    "\n",
    "for log_name, resp_df in log_d.items():\n",
    "    # Parse country, target domain, and AS number based on log_name\n",
    "    dot_loc_i = log_name.find(\".\")\n",
    "    as_number_i = int(log_name[:dot_loc_i])\n",
    "    country_s = log_name[dot_loc_i+1:dot_loc_i+3]\n",
    "    domain_s = log_name[dot_loc_i+4:]\n",
    "    \n",
    "    if resp_df.empty:\n",
    "        fqdn_set = set()\n",
    "        is_reachable = False\n",
    "    else:\n",
    "        # Convert the DataFrame into Series\n",
    "        # Please note that the column name in DataFrame is 0.\n",
    "        resp_ser = resp_df[0].squeeze()\n",
    "        fqdn_set, is_reachable = produce_fqdn(resp_ser)\n",
    "\n",
    "    # Collect into lists\n",
    "    country_l.append(country_s)\n",
    "    domain_l.append(domain_s)\n",
    "    as_number_l.append(as_number_i)\n",
    "    n_fqdn_response_l.append(len(fqdn_set))\n",
    "    is_reachable_l.append(is_reachable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f9194e-625b-4525-a41e-07058e78bde4",
   "metadata": {},
   "source": [
    "# 4. Create a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63ae6477-c991-4215-b397-ec3abbf8e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_l = [\"country\", \"target_domain\", \"as_number\", \"#fqdn_in_response\", \"is_reachable\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "828d00b1-d262-40ea-9b6a-08cbe921c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(country_l, domain_l, as_number_l, n_fqdn_response_l, is_reachable_l)), columns = col_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b60103d-e05f-48b8-9747-6f308d2a031b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir(output_path_s)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd0b17e-1109-4e50-afe3-42d4e4412232",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"de.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab8f3f-6ad3-4d31-895c-ff04beec86f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
