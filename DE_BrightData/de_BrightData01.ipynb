{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "790f4bc2-13a6-4442-9046-a16d388e3a2d",
   "metadata": {},
   "source": [
    "# 1. Import packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46e31b02-cee2-48f2-a080-bc9002d9eab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import json\n",
    "import os\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29aa2c4c-18b0-4e4f-9973-41f0aca66637",
   "metadata": {},
   "source": [
    "# 2. Read a txt file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b39d166-44bb-4bd8-94f3-94cf14b48926",
   "metadata": {},
   "source": [
    "## 2.1. Change to inputs directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14a728eb-5ed9-4c0e-b528-7c0ada2dbca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/immanuel/Documents/NEU/05_Spring_2022/CS7675_ResAppr/tasks/MyLab/task14_de_BrightData\n",
      "/Users/immanuel/Documents/NEU/05_Spring_2022/CS7675_ResAppr/tasks/MyLab/task14_de_BrightData/inputs/logs\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "input_path_s = \"/inputs/logs\"\n",
    "input_path_s = os.getcwd() + input_path_s\n",
    "output_path_s = \"/outputs\"\n",
    "output_path_s = os.getcwd() + output_path_s\n",
    "os.chdir(input_path_s)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e460e1df-de0e-476a-9c23-4090224f450a",
   "metadata": {},
   "source": [
    "## 2.2. Read all txt log files and collect them in a dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7293e8b2-5472-4a3a-b312-5eed9eeeedae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DUPLICATE LOG FILE: 2022071\n",
      "8009\n"
     ]
    }
   ],
   "source": [
    "log_d = dict()\n",
    "\n",
    "for file in glob.glob(\"*.txt\"):\n",
    "    \n",
    "    # Get the txt filename without the extension\n",
    "    txt_filename = os.path.splitext(file)[0]\n",
    "    \n",
    "    if txt_filename[:1].isdigit():\n",
    "    \n",
    "        # Parse AS number from txt_filename\n",
    "        dot_loc_i = txt_filename.find(\".\")\n",
    "        as_number_s = txt_filename[:dot_loc_i]\n",
    "\n",
    "        # If there is a number at the end of the filename, then remove.\n",
    "        if txt_filename[-1].isdigit():\n",
    "            txt_filename = txt_filename[:-1]\n",
    "\n",
    "        # Try whether txt_filename is in the dictionary\n",
    "        # If not, then assign into the dictionary\n",
    "        try:\n",
    "            log_d[txt_filename]\n",
    "            print(f\"DUPLICATE LOG FILE: {txt_filename}\")\n",
    "        except:\n",
    "            if os.path.getsize(file) > 500:\n",
    "                log_d[txt_filename] = pd.read_csv(file, sep=\"\\n\", header=None, on_bad_lines='skip')\n",
    "            else:\n",
    "                log_d[txt_filename] = pd.DataFrame()\n",
    "    \n",
    "print(len(log_d))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f11bd0b2-38d8-4fd4-8248-1760a897496f",
   "metadata": {},
   "source": [
    "# 3. Count Request URL: FQDN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3047b8d-687a-4733-9c9f-97d0d6c48012",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_fqdn(request_series):\n",
    "    '''\n",
    "    parameter: path of txt files\n",
    "    output: list of txt files\n",
    "    does: Read all txt files in the path and creates a list of them\n",
    "    '''\n",
    "    fqdn_set = set()\n",
    "    is_reachable = True\n",
    "    for req in request_series:\n",
    "        if req[:15] == \"{'request url':\":\n",
    "            slash_loc_i = req.find(\"/\")\n",
    "            comma_loc_i = req.find(\",\")\n",
    "            url = req[slash_loc_i+2:comma_loc_i-1]\n",
    "\n",
    "            slash_loc_i = url.find(\"/\")\n",
    "            if slash_loc_i > 0:\n",
    "                url = url[:slash_loc_i]\n",
    "\n",
    "            question_mark_loc_i = url.find(\"?\")\n",
    "            if question_mark_loc_i > 0:\n",
    "                url = url[:question_mark_loc_i]\n",
    "\n",
    "            if \".\" in url:\n",
    "                fqdn_set.add(url)\n",
    "        else:\n",
    "            if req[-9:] == \"<unknown>\":\n",
    "                is_reachable = False         \n",
    "            \n",
    "    return fqdn_set, is_reachable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7228efb6-b34b-4aeb-abea-bed52c105ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "country_l = []\n",
    "domain_l = []\n",
    "as_number_l = []\n",
    "n_fqdn_response_l = []\n",
    "is_reachable_l = []\n",
    "\n",
    "for log_name, resp_df in log_d.items():\n",
    "    # Parse country, target domain, and AS number based on log_name\n",
    "    dot_loc_i = log_name.find(\".\")\n",
    "    as_number_i = int(log_name[:dot_loc_i])\n",
    "    country_s = log_name[dot_loc_i+1:dot_loc_i+3]\n",
    "    domain_s = log_name[dot_loc_i+4:]\n",
    "    \n",
    "    if resp_df.empty:\n",
    "        fqdn_set = set()\n",
    "        is_reachable = False\n",
    "    else:\n",
    "        # Convert the DataFrame into Series\n",
    "        # Please note that the column name in DataFrame is 0.\n",
    "        resp_ser = resp_df[0].squeeze()\n",
    "        fqdn_set, is_reachable = produce_fqdn(resp_ser)\n",
    "\n",
    "    # Collect into lists\n",
    "    country_l.append(country_s)\n",
    "    domain_l.append(domain_s)\n",
    "    as_number_l.append(as_number_i)\n",
    "    n_fqdn_response_l.append(len(fqdn_set))\n",
    "    is_reachable_l.append(is_reachable)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5f9194e-625b-4525-a41e-07058e78bde4",
   "metadata": {},
   "source": [
    "# 4. Create a CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "63ae6477-c991-4215-b397-ec3abbf8e0ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_l = [\"country\", \"target_domain\", \"as_number\", \"#fqdn_in_response\", \"is_reachable\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "828d00b1-d262-40ea-9b6a-08cbe921c826",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list(zip(country_l, domain_l, as_number_l, n_fqdn_response_l, is_reachable_l)), columns = col_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b60103d-e05f-48b8-9747-6f308d2a031b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/immanuel/Documents/NEU/05_Spring_2022/CS7675_ResAppr/tasks/MyLab/task14_de_BrightData/inputs/logs\n",
      "/Users/immanuel/Documents/NEU/05_Spring_2022/CS7675_ResAppr/tasks/MyLab/task14_de_BrightData/outputs\n"
     ]
    }
   ],
   "source": [
    "print(os.getcwd())\n",
    "os.chdir(output_path_s)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4fd0b17e-1109-4e50-afe3-42d4e4412232",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"de.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86ab8f3f-6ad3-4d31-895c-ff04beec86f3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
